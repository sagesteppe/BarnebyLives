elucidate::mean_ci(x$Records, replicates = 1000, ci_level = 0.99))
)
) |>
bind_rows() |>
mutate(Percent = 1:100)
#################################################################################
fp <- scouting[scouting$futurePotential=='Yes',]
fp <- arrange(fp, suitability) |>
st_drop_geometry() |>
select(suitability) |>
mutate(obs = 1:n() / n())
### Here we prep some display text which will help users interpret the plot ####
################################################################################
sm50 <- suitability_means[ which.min(abs(suitability_means$Percent-50)), ]
# on average 50% of cells have lower probabilities of being suitable than 0.23
sm80 <- suitability_means[ which.min(abs(suitability_means$Percent-80)), ]
# on average 80% of cells have lower probabilities of being suitable than 0.614
fp_2 <- fp[ which.min(abs(fp$obs-0.2)), ] # 80% of all populations are found in areas with suitability > 65.2%
fp_5 <- fp[ which.min(abs(fp$obs-0.5)), ] # 50% of all populations are found in areas with suitability > 83.6%
fp_8 <- fp[ which.min(abs(fp$obs-0.8)), ] # the final 20 % of populations are found in areas with suitability > 94.6%
labs <- data.frame(
x = c(
round(fp_2$obs, 2)*100 -10,
round(fp_5$obs, 2)*100 - 10,
sm50$Percent+15,
sm80$Percent+15),
y = c(
round(fp_2$suitability, 2) + 0.1,
round(fp_5$suitability, 2) + 0.1,
sm50$mean - 0.15,
sm80$mean - 0.15),
label = c(
paste0(100- (round(fp_2$obs, 2)*100), '% of pops.\nwere found in areas\nwith suitability > ', round(fp_2$suitability, 2)),
paste0(round(fp_5$obs, 2)*100, '% of pops.\nwere found in areas\nwith suitability > ', round(fp_5$suitability, 2)),
paste0(sm50$Percent, '% of cells have\nprobabilities of being\nsuitable lower than ', round(sm50$mean, 2)),
paste0(sm80$Percent, '% of cells have\nprobabilities of being\nsuitable lower than ', round(sm80$mean, 2))
)
)
################################################################################
# Create the mean suitability values across all taxa, this will illustrate the
# distribution of modeled suitable habitat across 'common species' in the West based
# on our input data and modelling approach.
suitability_means <- suitability_means |>
mutate(Null_mod = mean*Percent)
## create a dummy species var to put the grey50 color on the legend.
dum_species <- data.frame(Percent = 1, Records = 0.1, Species = 'dum')
linecols <- c( # define our palette
'Species' = 'grey50',
"Mean (95% CI)" = "#093824",
"95% CI" = "#73BA9B",
"Observed Populations" = "#7570b3",
'Theoretical Probability' = '#d95f02'
)
ggplot(suitability_amounts,
aes(x = Percent, y = Records, color = Species, group = Species)) +
geom_line(lty = 1) +
scale_color_grey(guide = 'none') +
ggnewscale::new_scale_color() +
geom_ribbon(data = suitability_means, aes(ymin = lower, ymax = upper, x = Percent, fill = '95% CI'),
inherit.aes = F, alpha = 0.5) +
geom_line(data = suitability_means,
aes(x = Percent, y =  mean, color = 'Mean (95% CI)'),
inherit.aes = F, lwd = 1) +
geom_line(data = suitability_means, aes(y = Percent/100, x = Null_mod, color = 'Theoretical Probability'),
inherit.aes = F, lwd = 1) +
geom_line(data = fp, aes(y = suitability, x = obs*100, color = 'Observed Populations'), inherit.aes = F, lwd = 1) +
geom_line(data = dum_species, aes(color = 'Species'), lwd = 1) +
labs(
title = 'Populations are found in areas\nwith higher predicted suitability',
x = "Raster Cells (cumulative)",
y = 'Predicted Suitability') +
theme_classic() +
scale_y_continuous(
breaks = seq(0, 1, by = 0.2)
)  +
scale_fill_manual(values = linecols, guide = 'none') +
scale_colour_manual(
values = linecols, name = NULL,
breaks = c('Species', 'Mean (95% CI)', 'Theoretical Probability', 'Observed Populations')) +
scale_x_continuous(
breaks = seq(0, 100, by = 20), labels = \(x) paste0(x, "%"),
sec.axis = sec_axis(~., name = 'Populations Found (cumulative)',
breaks = seq(0, 100, by = 20), labels = \(x) paste0(x, "%"))) +
theme(
legend.position=c(.9,.10),
plot.title = element_text(hjust = 0.5),
aspect.ratio = 1/1) +
geom_segment(
aes(
xend = fp_2$obs*100,
yend = fp_2$suitability,
x = round(fp_2$obs, 2)*100 - 10,
y = fp_2$suitability + 0.1),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_segment(
aes(
xend = fp_5$obs*100,
yend = fp_5$suitability,
x = round(fp_5$obs, 2)*100 - 10,
y = fp_5$suitability + 0.1),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_segment(aes(xend = sm50$Percent, yend = sm50$mean,
x = sm50$Percent+15, y = sm50$mean - 0.15),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_segment(aes(xend = sm80$Percent, yend = sm80$mean,
x = sm80$Percent+15, y = sm80$mean - 0.15),
arrow = arrow(length = unit(0.25, "cm")), color = 'black') +
geom_label(data = labs, aes(x = x, y = y, label = label),
inherit.aes = F, size = 3 ,
######        USE THIS TO MAKE THE PLOT TRANSPARENT FOR THE TALK        #####
fill='transparent', color = 'white') +
theme(
axis.text = element_text(color = 'white'),
axis.ticks = element_line(color = 'white'),
panel.background = element_rect(fill='transparent'), #transparent panel bg
plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
panel.grid.major = element_blank(), #remove major gridlines
panel.grid.minor = element_blank(), #remove minor gridlines
legend.background = element_rect(fill='transparent'), #transparent legend bg
legend.box.background = element_rect(fill='transparent'), #transparent legend panel
text = element_text(colour = "white")
)
ggsave('../plots/leafplot-trans.png', width = 9, height = 9, units = 'in')
rm(fp, fp_2, fp_5, fp_8, labs, prctn, sm50, sm80, linecols)
fp <- scouting[scouting$futurePotential=='Yes',]
quants <- quantile(fp$suitability, na.rm = TRUE, probs = c(0.25, 0.5, 0.75))
hist(fp$suitability)
abline(v = quants[[1]], lwd = 2)
abline(v = quants[[2]], lwd = 2)
hist(fp$Rank)
scout1 <- mutate(
scout1,
taxa = as.factor(taxa),
COLL_ID = as.factor(COLL_ID))
scout_long |>
sf::st_drop_geometry() |>
write.csv('../data/SOS/LandscapeMetrics.csv', row.names  = F)
scout_long <- pivot_longer(scouting, cai:enn_mn)
scout_long <- mutate(
scout_long,
POP_CENSUS_SQRT = sqrt(POPULATION_SIZE),
POP_CENSUS_LOG = log(POPULATION_SIZE)
)
scout_long |>
sf::st_drop_geometry() |>
write.csv('../data/SOS/LandscapeMetrics.csv', row.names  = F)
id <- Sys.getenv("CDSE_ID")
secret <- Sys.getenv("CDSE_SECRET")
OAuthClient <- GetOAuthClient(id = id, secret = secret)
library(CDSE)
dsn <- system.file("extdata", "luxembourg.geojson", package = "CDSE")
aoi <- sf::read_sf(dsn, as_tibble = FALSE)
images <- SearchCatalog(aoi = aoi, from = "2023-07-01", to = "2023-07-31",
collection = "sentinel-2-l2a", with_geometry = TRUE, client = OAuthClient)
OAuthClient <- GetOAuthClient(id = id, secret = secret)
day <- images[order(images$tileCloudCover), ]$acquisitionDate[1]
library(CDSE)
SearchCatalogByTimerange
?SearchCatalogByTimerange
# devtools::install_github('sagesteppe/BarnebyLives', force = TRUE)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
library(textclean)
moj <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry Mojave - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number)) %>%
data.frame()
data <- moj
View(moj)
data <- dms2dd(data)
data <- autofill_checker(data)
data <- coords2sf(data)
# write out KMLs for people to verify that their coordinates are correct.
d_split <- dplyr::group_split(data, !!as.name('Primary_Collector'))
for (i in seq_along(d_split)){
geodata_writer(
d_split[[i]],
filename = gsub(' ', '_', unique(d_split[[i]]$Primary_Collector)),
path = '../kmls')
}
rm(d_split, i)
p2geo <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'UNIQUEID', path = p2geo)
data <- physical_grabber(data, path = p2geo)
data <- site_writer(data, path = p2geo)
p2tax <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
data <- data |>
unite(Full_name, c('Genus', 'Epithet', 'Infrarank', Infraspecies),
remove = F, na.rm = TRUE, sep = ' ')
data <- drop_na(data, Genus)
data <- spell_check(data = data, column = 'Full_name', path = p2tax)
data <- family_spell_check(data, path = p2tax)
data <- author_check(data, path = p2tax)
data <- associates_spell_check(data, 'Associates', path = p2tax) # we can run on both columns.
data <- associates_spell_check(data, 'Vegetation', path = p2tax)
data <- associate_dropper(data, 'Full_name', col  = 'Associates')
data <- associate_dropper(data, 'Full_name', col  = 'Vegetation')
data <- date_parser(data, coll_date = 'Date_digital', det_date = 'Determined_date')
rm(p2geo, p2tax)
# just overwrite the original Associates and Vegetation columns
data <- data %>%
select(-Associates, -Vegetation) |>
rename(Associates = 'SpellCk.Associates', Vegetation = 'SpellCk.Vegetation')
# honestly just overwrite these too.
data <- data %>%
select(-SpellCk.gGRP, -Match, -SpellCk.taxon_rank,
-Full_name, -Genus, -Epithet, -Infrarank, -Infraspecies) |>
rename(Full_name = SpellCk.taxon_name, Genus = SpellCk.genus, Epithet = SpellCk.species,
Infrarank = SpellCk.infraspecific_rank, Infraspecies = SpellCk.infraspecies)
# we keep these processes in a discrete chunk set not to evaluate so as to not overwhelm
# the services. Google does charge if the number of queries per month is high.
names <- sf::st_drop_geometry(data) %>%
pull(Full_name)
pow_res <- lapply(names,
powo_searcher) %>%
bind_rows()
data <- bind_cols(data, pow_res)
rm(names, pow_res)
data <- data %>%
sf::st_as_sf()
#SoS_gkey = Sys.getenv("Sos_gkey")
#data <- directions_grabber(data, api_key = SoS_gkey)
View(moj)
View(data)
# I don' like Senecio crassulus for S. int, I also don't like
# Wyethia sagittata , nor Caralluma subulata
skips <- c('Grindelia camporum', 'Asclepias subulata', 'Amsinckia retrorsa', 'Sagittaria montevidensis subsp. calycina', 'Balsamorhiza sagittata', 'Astragalus mollissimus')
data <- sf::st_drop_geometry(data)
skipped <- filter(data, Full_name %in% skips) %>%
mutate(
Family = POW_Family,
Infrarank = if_else(Full_name == 'Sagittaria montevidensis subsp. calycina', 'subsp.', NA),
Infraspecies = if_else(Full_name == 'Sagittaria montevidensis subsp. calycina', 'calycina', NA),
Infraspecific_authority = if_else(Full_name == 'Sagittaria montevidensis subsp. calycina', '(Engelm.) Bogin', NA),
Binomial_authority = case_when(
Full_name == 'Grindelia camporum' ~ 'Greene',
Full_name == 'Asclepias subulata' ~ 'Decne.',
Full_name == 'Amsinckia retrorsa' ~ 'Suksd.',
Full_name == 'Balsamorhiza sagittata' ~ '(Pursh) Nutt.',
Full_name == 'Sagittaria montevidensis subsp. calycina' ~ 'Cham. & Schltdl.',
),
Slope = slope,
Aspect = aspect
#  Epithet = if_else('Sagittaria montevidensis subsp. calycina', 'montevidensis', Epithet),
) |>
unite(Name_authority,
Genus, Epithet, Binomial_authority, Infrarank, Infraspecies, Infraspecific_authority,
remove = F, na.rm = T, sep = ' ')
# skipped <- split_scientificName(skipped, 'POW_Name_authority')
d_sub <- data %>%
filter(! Full_name %in% skips) %>%
mutate(
Family = POW_Family,
Infrarank = POW_Infrarank,
Infraspecies = POW_Infraspecies,
Infraspecific_authority = POW_Infra_authority,
Name_authority = POW_Name_authority,
Binomial_authority = POW_Binom_authority,
Genus = POW_Genus,
Epithet = POW_Epithet,
Slope = slope,
Aspect = aspect
)
data1 <- bind_rows(skipped, d_sub) |>
# d_sub |>
#filter(Primary_Collector != 'Rosalind Rowe') |>
arrange(Primary_Collector, as.numeric(Collection_number))
rm(d_sub, skipped, skips)
# first ensure the columns are in the same order as google sheets
processed_cols <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
colnames()
# first ensure the columns are in the same order as google sheets
processed_cols <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
colnames()
df <- data1 %>%
sf::st_drop_geometry() %>%
relocate(any_of(processed_cols)) %>%
arrange(Primary_Collector, Collection_number)
df |>
filter(Primary_Collector %in%
c('Jennifer Schmidley', 'Susana Calvillo', 'Sylvie Harris', 'Andrew Lisak', 'Rebecca Ubalde')) |>
write_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Mojave - 2024')
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
dir.create('../HerbariumLabels/raw')
dir.create('../HerbariumLabels/raw/Andy-raw')
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
data <- read.csv('../results/collections-Andrew_Lisak.csv') |>
dplyr::filter(Collection_number == params$Collection_number) |>
sf::st_drop_geometry()
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed California - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Mojave - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
dir.create('../HerbariumLabels/raw')
dir.create('../HerbariumLabels/raw/Andy-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Andy-raw'
purrr::walk(
.x = proc_split[['Andy Lisak']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Andy.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed California - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed COPL - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Mojave - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed
View(processed)
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Andy-raw'
purrr::walk(
.x = proc_split[['Andy Lisak']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Andy.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
data <- read.csv('../results/collections-Andrew_Lisak.csv') |>
dplyr::filter(Collection_number == params$Collection_number) |>
sf::st_drop_geometry()
purrr::walk(
.x = proc_split[['Andy Lisak']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Andy.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
View(processed)
View(proc_split)
proc_split[['Andy Lisak']]$Collection_number
proc_split[['Andy Lisak']]
proc_split[['Andrew Lisak']]
purrr::walk(
.x = proc_split[['Andrew Lisak']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Andy.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
collection_examples
library(BarnebyLives)
collection_examples
format_database_import
load("/media/steppe/hdd/BarnebyLives/data/database_templates.rda")
View(database_templates)
View(database_templates)
unique(datatbase_templatse$Database)
unique(datatbase_templates$Database)
unique(database_templates$Database)
dat_import <- format_database_import(collection_examples, 'Symbiota') |>
dplyr::mutate(
dplyr::across(
dplyr::everything(), ~ as.character(.)),
dplyr::across(
dplyr::everything(), ~ tidyr::replace_na(., '')))
View(dat_import)
data('collection_examples')
p2libs <- system.file(package = 'BarnebyLives')
p2libs <- system.file(package = 'BarnebyLives')
folds <- file.path(
'BarnebyLives', 'rmarkdown', 'templates', 'labels', 'skeleton', 'skeleton.Rmd')
file.copy(from = file.path(p2libs, folds), to =  '.')
?file.copy
file.copy(from = file.path(p2libs, folds), to =  '.', showWarnings = FALSE)
file.copy(from = file.path(p2libs, folds), to =  '.', showWarnings = FAlse)
file.copy(from = file.path(p2libs, folds), to =  '.', showWarnings = FALSE)
file.path(p2libs, folds)
folds <- file.path(
'BarnebyLives', 'rmarkdown', 'templates', 'SoS_transmittal', 'skeleton', 'skeleton.Rmd')
file.copy(from = file.path(p2libs, folds), to =  '.')
file.path(p2libs, folds)
folds <- file.path(
'BarnebyLives', 'rmarkdown', 'templates', 'SoS_transmittal', 'skeleton', 'skeleton.Rmd')
remotes::install_github('sagesteppe/BarnebyLives')
library(BarnebyLives)
library(tidyverse)
abbrevs <- read.csv(
file.path(
system.file(package = 'BarnebyLives'),
'data-raw', 'ipni_author_abbreviations.csv')
)
data(ipni_authors)
remotes::install_github('sagesteppe/BarnebyLives')
library(BarnebyLives)
library(tidyverse)
library(sf)
library(sf)
library(terra)
data(ipni_authors)
ipni_authors
read.csv('data-raw/ipni_author_abbreviations.csv')
read.csv('./data-raw/ipni_author_abbreviations.csv')
getwd()
read.csv('../data-raw/ipni_author_abbreviations.csv')
abbrevs <- read.csv('../data-raw/ipni_author_abbreviations.csv')
trailed <- vector(mode = 'character', length = nrow(abbrevs))
trailed[grep('\\.$', abbrevs$author_abbrevation)] <- '.'
abbrevs_spaced <- sub('\\.$', '', abbrevs$author_abbrevation) # remove the trailing periods
abbrevs_notrail <- sub('\\.(?!.*\\.)', ". ",
abbrevs_spaced, perl = T) # identify the last period in the name, and add a space after it
abbrevs <- paste0(abbrevs_notrail, t)
abbrevs <- paste0(abbrevs_notrail, trailed)
abbrevs
saveRDS(ipni_author_abbreviations)
ipni_authors <- abbrevs
saveRDS(ipni_author_abbreviations)
saveRDS(ipni_authors)
ipni_authors
saveRDS(ipni_authors)
usethis::use_data(ipni_authors)
load("/media/steppe/hdd/BarnebyLives/data/ipni_authors.rda")
data("ipni_authors")
p2 <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data' # note we have downloaded it
write.csv(ipni_authors, file.path(p2, 'ipni_author_abbreviations.csv'))
data("ipni_authors")
remotes::install_github('sagesteppe/BarnebyLives')
data("ipni_authors")
write.csv(ipni_authors, file.path(p2, 'ipni_author_abbreviations.csv'))
data("ipni_authors")
head(ipni_authors)
load("/media/steppe/hdd/BarnebyLives/data/ipni_authors.rda")
data(ipni_authors)
load("/media/steppe/hdd/BarnebyLives/data/ipni_authors.rda")
data(ipni_authors)
data(ipni_authors, package='BarnebyLives')
data('ipni_authors', package='BarnebyLives')
ipni_authors
ipni_authors
'ipni_authors'
data('ipni_authors')
load("/media/steppe/hdd/BarnebyLives/data/ipni_authors.rda")
# prepare material for authorship table.
setwd('/media/steppe/hdd/BarnebyLives/data-raw')
abbrevs <- read.csv('ipni_author_abbreviations.csv')
trailed <- vector(mode = 'character', length = nrow(abbrevs))
trailed[grep('\\.$', abbrevs$author_abbrevation)] <- '.'
abbrevs_spaced <- sub('\\.$', '', abbrevs$author_abbrevation) # remove the trailing periods
abbrevs_notrail <- sub('\\.(?!.*\\.)', ". ",
abbrevs_spaced, perl = T) # identify the last period in the name, and add a space after it
abbrevs <- paste0(abbrevs_notrail, trailed)
ipni_authors <- abbrevs
usethis::use_data(ipni_authors)
data(ipni_authors)
ipni_authors
