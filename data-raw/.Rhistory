}
# now ensure the datum is appropriate for each point
x[datum_name] <- sapply( as.character(x[datum_name]), dat_check)
crs_lkp = data.frame(
datum = c('NAD27', 'NAD83', 'WGS84'),
crs = c(4267, 4269, 4326))
colnames(crs_lkp)[1] <- datum_name
x <- dplyr::left_join(x, crs_lkp, by = datum_name)
# separate all points by there datum
dat_list <- split(x, f = x[datum_name])
if(length(dat_list) == 1) {
dat_list <- dplyr::bind_rows(dat_list)
crss <- dat_list$crs[1]
dat_list <- dat_list |>
sf::st_as_sf(coords = c(x = 'longitude_dd', y = 'latitude_dd'),
crs = crss, remove = F) |>
sf::st_transform(4326) |>
dplyr::select(-crs) |>
dplyr::mutate(datum = 'WGS84', .before = geometry)
} else {
dat_list <- purrr::map(dat_list, . |>
sf::st_as_sf(., coords = c(x = 'longitude_dd', y = 'latitude_dd'),
crs = .$crs[1], remove = F) |>
sf::st_transform(4326)) |>
dplyr::bind_rows() %>%
dplyr::select(-crs) %>%
dplyr::mutate(datum = 'WGS84', .before = geometry)
}
return(dat_list)
}
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'Collection_number', path = p)
p <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
data <- spell_check(data, path = p)
#' check that genera and specific epithets are spelled (almost) correctly
#'
#' @description this function attempts to verify the spelling of a user submitted taxonomic name. If necessary it will proceed step-wise by name pieces attempting to place them.
#' @param x data frame/ tibble /sf object containing names to spell check
#' @param y a column in it containing a full scientific name
#' @param path a path to a folder containing the taxonomic data.
#' @examples
#' \dontrun{
#' names_vec <- c('Astagalus purshii', 'Linnaeus borealius', 'Heliumorus multifora')
#' spelling <- spell_check(names_vec, path = '../taxonomic_data')
#' spelling
#' }
#' @export
spell_check <- function(x, path) {
# first verify that the points have coordinates.
r <- sapply( x[c('Genus', 'Epithet' )], is.na)
g <- which(r[,1] == TRUE); s <- which(r[,2] == TRUE)
remove <- unique(c(g, s))
if(length(remove) > 0) {
x <- x[-remove,]
cat('Error with row(s): ', remove,
' continuing without.')
return(x)
}
rm(r, s, g, remove)
sppLKPtab <- read.csv(file.path(path, 'species_lookup_table.csv'))
genLKPtab <- read.csv(file.path(path, 'genus_lookup_table.csv'))
pieces <- unlist(stringr::str_split(x, pattern = " "))
genus <- pieces[1] ; species <- pieces[2]
binom <- paste(genus, species)
# infra species should be found without much hassle due to their length
if(length(pieces) == 4){
infras <- na.omit(sppLKPtab)
full_name <- paste(genus, species,
stringr::str_replace(pieces[3], 'ssp\\.|ssp', 'subsp.'), pieces[4])
if (any(grep( x = infras$scientificName, pattern = full_name, fixed = T))) {
return(data.frame(Query = x, Result = full_name, Match = 'exact'))
} else {
infraspecies_name <-
infras[which.min(adist(full_name, infras$scientificName)), 'scientificName'] |>
as.character()
return(data.frame(Query = x, Result = infraspecies_name, Match = 'fuzzy'))
}
# species can become difficult due to their short  names, e.g. 'Poa annua'
} else {
if (any(grep( x = sppLKPtab$scientificName, pattern = binom, fixed = T))) {
return(data.frame(Query = x, Result = x, Match = 'exact'))
} else{
# try and determine which piece is incorrect.
# subset datasets to query each name component separately
genus2char <- stringr::str_extract(genus, '[A-Z][a-z]{1}')
species3char <- stringr::str_extract(species, '[a-z]{3}')
gen_strings <-
dplyr::filter(genLKPtab, Grp == genus2char) |> dplyr::pull(strings)
spe_strings <-
dplyr::filter(sppLKPtab, Grp == species3char) |> dplyr::pull(scientificName)
# check to see if both genus and species are clean
if (any(grep(x = gen_strings, pattern = paste0('^', genus, '$')))) {
clean_genus_Tag <- genus
} else {
possible_genus_Tag <-
gen_strings[which.min(adist(genus, gen_strings))]
}
# is species clean
if (any(grep(x = spe_strings, pattern = paste0('^', species, '$')))) {
clean_species_Tag <- species
} else {
possible_species_Tag <-
spe_strings[which.min(adist(species, spe_strings))]
}
# if both the genus and species name are present, we could be missing it from the DB
if (exists('clean_genus_Tag') & exists ('clean_species_Tag'))
{
return(data.frame(
Query = x, Result = binom, Match = 'Suspected missing from ref DB'))
} else { # if one is not clean search them with the 'cleaned' up versions
combos <- ls()[grep(ls(), pattern = 'Tag')]
search_q <-
combos[c(grep(combos, pattern = 'genus'),
grep(combos, pattern = 'species'))]
search_nom <- paste(unlist(mget(search_q)), collapse = " ")
if (any(grep(x = sppLKPtab$scientificName, pattern = search_nom, fixed = T))) {
return(data.frame(Query = x, Result = search_nom, Match = 'fuzzy'))
} else{
possible_binomial <-
sppLKPtab[which.min(adist(search_nom, sppLKPtab$scientificName)), 'scientificName'] |>
as.character()
return(data.frame(Query = x, Result = possible_binomial, Match = 'fuzzy'))
}
}
}
}
}
data <- spell_check(data, path = p)
dat_out <- powo_seacher(data)
directions2site <- directions_grabber(data, api_key = SoS_gkey)
View(data)
st_crs(data)
sf::st_crs(data)
View(data)
data <- political_grabber(data, y = 'Collection_number', path = p)
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'Collection_number', path = p)
head(data) # now we can see that it is an sf object
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'Collection_number', path = p)
data <- site_writer(data, path = p)
data <- physical_grabber(data, path = p)
p <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
data <- spell_check(data, path = p)
View(spell_check)
function(x, path) {
# first verify that the points have coordinates.
r <- sapply( x[c('Genus', 'Epithet' )], is.na)
g <- which(r[,1] == TRUE); s <- which(r[,2] == TRUE)
remove <- unique(c(g, s))
if(length(remove) > 0) {
x <- x[-remove,]
cat('Error with row(s): ', remove,
' continuing without.')
return(x)
}
rm(r, s, g, remove)
sppLKPtab <- read.csv(file.path(path, 'species_lookup_table.csv'))
genLKPtab <- read.csv(file.path(path, 'genus_lookup_table.csv'))
pieces <- unlist(stringr::str_split(x, pattern = " "))
genus <- pieces[1] ; species <- pieces[2]
binom <- paste(genus, species)
# infra species should be found without much hassle due to their length
if(length(pieces) == 4){
infras <- na.omit(sppLKPtab)
full_name <- paste(genus, species,
stringr::str_replace(pieces[3], 'ssp\\.|ssp', 'subsp.'), pieces[4])
if (any(grep( x = infras$scientificName, pattern = full_name, fixed = T))) {
return(data.frame(Query = x, Result = full_name, Match = 'exact'))
} else {
infraspecies_name <-
infras[which.min(adist(full_name, infras$scientificName)), 'scientificName'] |>
as.character()
return(data.frame(Query = x, Result = infraspecies_name, Match = 'fuzzy'))
}
# species can become difficult due to their short  names, e.g. 'Poa annua'
} else {
if (any(grep( x = sppLKPtab$scientificName, pattern = binom, fixed = T))) {
return(data.frame(Query = x, Result = x, Match = 'exact'))
} else{
# try and determine which piece is incorrect.
# subset datasets to query each name component separately
genus2char <- stringr::str_extract(genus, '[A-Z][a-z]{1}')
species3char <- stringr::str_extract(species, '[a-z]{3}')
gen_strings <-
dplyr::filter(genLKPtab, Grp == genus2char) |> dplyr::pull(strings)
spe_strings <-
dplyr::filter(sppLKPtab, Grp == species3char) |> dplyr::pull(scientificName)
# check to see if both genus and species are clean
if (any(grep(x = gen_strings, pattern = paste0('^', genus, '$')))) {
clean_genus_Tag <- genus
} else {
possible_genus_Tag <-
gen_strings[which.min(adist(genus, gen_strings))]
}
# is species clean
if (any(grep(x = spe_strings, pattern = paste0('^', species, '$')))) {
clean_species_Tag <- species
} else {
possible_species_Tag <-
spe_strings[which.min(adist(species, spe_strings))]
}
# if both the genus and species name are present, we could be missing it from the DB
if (exists('clean_genus_Tag') & exists ('clean_species_Tag'))
{
return(data.frame(
Query = x, Result = binom, Match = 'Suspected missing from ref DB'))
} else { # if one is not clean search them with the 'cleaned' up versions
combos <- ls()[grep(ls(), pattern = 'Tag')]
search_q <-
combos[c(grep(combos, pattern = 'genus'),
grep(combos, pattern = 'species'))]
search_nom <- paste(unlist(mget(search_q)), collapse = " ")
if (any(grep(x = sppLKPtab$scientificName, pattern = search_nom, fixed = T))) {
return(data.frame(Query = x, Result = search_nom, Match = 'fuzzy'))
} else{
possible_binomial <-
sppLKPtab[which.min(adist(search_nom, sppLKPtab$scientificName)), 'scientificName'] |>
as.character()
return(data.frame(Query = x, Result = possible_binomial, Match = 'fuzzy'))
}
}
}
}
}
data <- spell_check(data, path = p)
View(data)
data <- spell_check(data, path = p)
data <- spell_check(data[2:3,], path = p)
View(coords2sf)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
df <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry - Examples') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
# determine whether these data have already been processed by the script, using
# a unique combination of collection name and collection code.
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
select(Collection_number, Primary_Collector) %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
input <- filter(df, ! UNIQUEID %in% processed$UNIQUEID ) %>%
select(-UNIQUEID)
rm(processed, df)
install.packages('BarnebyLives')
install.packages("BarnebyLives")
devtools::insall_github('sagesteppe/BarnebyLives')
devtools::install_github('sagesteppe/BarnebyLives')
library(tidyverse)
library(BarnebyLives)
# devtools::install_github('sagesteppe/BarnebyLives')
library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
df <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry - Examples') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
# determine whether these data have already been processed by the script, using
# a unique combination of collection name and collection code.
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
select(Collection_number, Primary_Collector) %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
input <- filter(df, ! UNIQUEID %in% processed$UNIQUEID ) %>%
select(-UNIQUEID)
rm(processed, df)
data <- date_parser(input, 'Date_digital')
dplyr::select(data, starts_with('Date')) %>%
utils::head()
data <- dms2dd(data, dms = F)
dplyr::select(data, starts_with(c('latitude', 'longitude'))) %>%
utils::head()
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'Collection_number', path = p)
head(data) # now we can see that it is an sf object
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'Collection_number', path = p)
data <- site_writer(data, path = p)
data <- physical_grabber(data, path = p)
p <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
data <- spell_check(data, path = p)
View(data)
dat_out <- powo_seacher(data)
SoS_gkey = Sys.getenv("Sos_gkey")
directions <- directions_grabber(data, api_key = SoS_gkey)
View(directions)
# we will add these data onto our final sheet.  THIS IS THE LAST STEP OF THIS TUTORIAL
sheet_append(directions, '1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples', data = df)
# we will add these data onto our final sheet.  THIS IS THE LAST STEP OF THIS TUTORIAL
sheet_append('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples', data = directions)
df <- st_drop_geometry(directions)
df <- sf::st_drop_geometry(directions)
# we will add these data onto our final sheet.  THIS IS THE LAST STEP OF THIS TUTORIAL
sheet_append('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples', data = df)
# we will add these data onto our final sheet.  THIS IS THE LAST STEP OF THIS TUTORIAL
sheet_append('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples', data = df)
View(directions)
dat_out <- powo_seacher(data)
#' notes: results are observed to fail for valid infraspecies on Kew's end, and they seem not
#' to mention valid infraspecies.
#' @examples
#' library(dplyr)
#' pow_results <- lapply(
#'       c('Linnaea borealis var. borealis', 'Astragalus purshii', 'Pinus ponderosa'),
#'       powo_searcher) |>
#'    dplyr::bind_rows()
#' head(pow_results)
#' @export
powo_searcher <- function(x){
query_results <- kewr::search_powo(x)
if (is.null(query_results[["results"]])) {
second_try <- try_again(query_results)
if (is.null(second_try[["results"]])) {
taxonomic_info <- data.frame(
family = as.character(),
name_authority = as.character(),
full_name = as.character(),
genus = as.character(),
epithet = as.character(),
infrarank = as.character(),
infraspecies = as.character(),
authority = as.character()
)
taxonomic_info[1,] <- 'NOT FOUND'
} else {
results_to_process <- second_try
}
} else {
results_to_process <- query_results
}
# this is the end of the process, return empty results without error, or real results
if (exists('taxonomic_info')) {
out_ob <- data.frame(cbind(query = x, taxonomic_info))
} else {
taxonomic_info <- result_grabber(results_to_process)
out_ob <- data.frame(cbind(query = x, taxonomic_info))
}
new_names <-  paste0('POW', '_',
stringr::str_to_sentence( colnames(out_ob) ))
colnames(out_ob) <- new_names
return(out_ob)
}
dat_out <- powo_seacher(data)
ls()
library(tidyverse)
library(BarnebyLives)
# devtools::install_github('sagesteppe/BarnebyLives')
library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
df <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry - Examples') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
# determine whether these data have already been processed by the script, using
# a unique combination of collection name and collection code.
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
select(Collection_number, Primary_Collector) %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
input <- filter(df, ! UNIQUEID %in% processed$UNIQUEID ) %>%
select(-UNIQUEID)
rm(processed, df)
data <- date_parser(input, 'Date_digital')
dplyr::select(data, starts_with('Date')) %>%
utils::head()
data <- dms2dd(data, dms = F)
dplyr::select(data, starts_with(c('latitude', 'longitude'))) %>%
utils::head()
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
data <- political_grabber(data, y = 'Collection_number', path = p)
data <- political_grabber(data, y = 'Collection_number', path = p)
View(data)
library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
df <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry - Examples') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
# determine whether these data have already been processed by the script, using
# a unique combination of collection name and collection code.
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
select(Collection_number, Primary_Collector) %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
input <- filter(df, ! UNIQUEID %in% processed$UNIQUEID ) %>%
select(-UNIQUEID)
rm(processed, df)
data <- date_parser(input, 'Date_digital')
dplyr::select(data, starts_with('Date')) %>%
utils::head()
data <- dms2dd(data, dms = F)
dplyr::select(data, starts_with(c('latitude', 'longitude'))) %>%
utils::head()
data1 <- coords2sf(data)
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
#' @examples mixed_datum <- data.frame(
#'  datum = (rep(c('nad27', 'NAD83', 'wGs84'), each = 5)),
#'  longitude_dd = runif(15, min = -120, max = -100),
#'  latitude_dd = runif(15, min = 35, max = 48)
#'  )
#'
#' wgs84_dat <- coords2sf( mixed_datum )
#' str(wgs84_dat)
#' sf::st_crs(wgs84_dat)
#' @export
coords2sf <- function(x, datum){
# first verify that the points have coordinates.
r <- sapply( x[c('latitude_dd', 'longitude_dd' )], is.na)
lat <- which(r[,1] == TRUE); long <- which(r[,2] == TRUE)
remove <- unique(c(lat, long))
if(length(remove) > 0) {
x <- x[-remove,]
cat('Error with row(s): ', remove,
' continuing without.')
}
rm(r, lat, long, remove)
if(missing(datum)){ # identify datum information
if(length(colnames(x)[grep('datum', colnames(x), ignore.case = T)]) == 1){
datum_name = colnames(x)[grep('datum', colnames(x), ignore.case = T)] } else {
x$datum = 'WGS84'
}
}
if(!exists('datum_name')){datum_name = 'datum'}
dat_check <- function(x){if(grepl('nad.*27', ignore.case = T, x = x)) {
x = "NAD27"} else if(grepl('nad.*83', ignore.case = T, x = x)) {
x = 'NAD83'} else if(grepl('wgs', ignore.case = T, x = x)) {
x = "WGS84"
} else {x = 'WGS84'}
}
# now ensure the datum is appropriate for each point
x[datum_name] <- sapply( as.character(x[datum_name]), dat_check)
crs_lkp = data.frame(
datum = c('NAD27', 'NAD83', 'WGS84'),
crs = c(4267, 4269, 4326))
colnames(crs_lkp)[1] <- datum_name
x <- dplyr::left_join(x, crs_lkp, by = datum_name)
# separate all points by there datum
dat_list <- split(x, f = x[datum_name])
if(length(dat_list) == 1) {
dat_list <- dplyr::bind_rows(dat_list)
crss <- dat_list$crs[1]
dat_list <- dat_list |>
sf::st_as_sf(coords = c(x = 'longitude_dd', y = 'latitude_dd'),
crs = crss, remove = F) |>
sf::st_transform(4326) |>
dplyr::select(-crs) |>
dplyr::mutate(datum = 'WGS84', .before = geometry)
} else {
dat_list <- purrr::map(dat_list, . |>
sf::st_as_sf(., coords = c(x = 'longitude_dd', y = 'latitude_dd'),
crs = .$crs[1], remove = F) |>
sf::st_transform(4326)) |>
dplyr::bind_rows() %>%
dplyr::select(-crs) %>%
dplyr::mutate(datum = 'WGS84', .before = geometry)
}
return(dat_list)
}
library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
df <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry - Examples') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(BarnebyLives)
label_info
data <- processed[i,]
processed
# read in data from the sheet to process
collection_examples <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples')
library(usethis)
library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
collection_examples <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples')
# read in data from the sheet to process
collection_examples <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples')
usethis::use_data(collection_examples)
setwd('/media/steppe/hdd/BarnebyLives/data-raw')
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
collection_examples <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples')
usethis::use_data(collection_examples)
data <- processed[i,]
data <- collection_examples[i,]
collection_examples
