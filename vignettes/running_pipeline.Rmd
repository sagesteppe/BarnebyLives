---
title: "running pipeline"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{running pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup}
library(tidyverse)
library(BarnebyLives)
# devtools::install_github('sagesteppe/BarnebyLives')
```


## load data into R

### load data from a local (on computer) source

Most users may 

### load data through google sheets

An alternative format for loading data is through Google Sheets. 
This can facilitate data-sharing and standardization by many collectors in different locations. 
This is the source of data which was used during beta-testing for development. 

We will use googlesheets4, which is a part of the tidyverse, but I do not think installs by default with the remainder of the 'verse. 
We will feed in the last part of the URL as the link to the path. 
If this is your first time using googlesheets4, it will walk you through a few steps to log into your google account so you can access data securely. 
After that googlesheets4 is actually really straightforward to use, note that I use the 'drive_auth' function here. 
This function makes non-interactive use easy, it is only used here because the vignette renders as a non-interactive format. 

```{r load through google sheets, eF}

library(googlesheets4)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
df <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M', 
                    sheet = 'Data Entry - Examples') %>% 
  mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))

```


### only process data which have not yet run through the pipeline. 

BarnebyLives takes a little bit of time to run, but it also requires the usage of Google Developer credits for 

```{r determine which data has been processed, eval = F}

# determine whether these data have already been processed by the script, using
# a unique combination of collection name and collection code. 
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
                        sheet = 'Processed - Examples') %>% 
  select(Collection_number, Primary_Collector) %>% 
  mutate(UNIQUEID = paste0(Primary_Collector, Collection_number))

input <- filter(df, ! UNIQUEID %in% processed$UNIQUEID ) %>% 
  select(-UNIQUEID)

rm(processed, df)
```


## Ensure Coordinates and Dates and formatted appropriately

Date parsing, e.g. convert date into congruent museum formats (month in roman numerals, or spelled out).
This step assumes that you are recording your dates in the American format of (month/day/year), rather than the internationally more common format (day/month/year). We will also parse out the day of month, month of year, and year, which is used in multiple possible downstream software.

```{r Date parsing}
data <- date_parser(input, 'Date_digital')

dplyr::select(data, starts_with('Date')) %>% 
  utils::head()
```

Conversion of Degrees Minutes Seconds (DMS) to Decimal Degrees (DD). 
The DMS format is still used in a few applications, such as the Seeds of Success program, we will convert this to the more generally utilized DD format. We will maintain both formats in the data set, so others have them readily available for other uses aside from creating herbarium labels. 

```{r Conversion of Degrees Minutes Seconds (DMS) to Decimal Degrees (DD)}
data <- dms2dd(data, dms = F)

dplyr::select(data, starts_with(c('latitude', 'longitude'))) %>% 
  utils::head()
```

For internal usage and data acquisition we will make data set explicitly spatial, rather than just holding coordinates in a column. 
This is also required to write out data in a format readable by Google Earth or another Geographic Information System. 

```{r Make dataset explicitly spatial}
data <- coords2sf(data)
head(data) # now we can see that it is an sf object
```


## Retrieve Political/Administrative Information

BarnebyLives! will retrieve various components of both political and administrative information. All of these data which include: The *state*, and *county* of collection, and the *township, range, section (TRS)* from the Public Land Survey System (PLSS). 
It will also determine whether a Federal or State Agency manages or owns the land which were collected from, and if so return the name of it. 
If either the United States Forest Service or Bureau of Land Management does manage the land, it will return information on grazing allotments.

Retrieve State, County, Ownership, TRS, and allotment information
```{r Retrieve Political, eval = F}
p <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'

data <- political_grabber(data, y = 'Collection_number', path = p)
```

## Geographic

Retrieve Nearest GNIS place name, and azimuth from it
```{r Retrieve Place and location from it, eval = F}
data <- site_writer(data, path = p)
```

## Site characteristics

Elevation (both meters and feet), Slope, Aspect, Surficial geology, and geomorphons

```{r, eval = F}
data <- physical_grabber(data, path = p)
```

## Taxonomic

BarnebyLives performs multiple operations related to taxonomy and nomenclature. The function **spell_check()**, will attempt to determine whether the supplied binomial scientific name, and family are spelled correctly and offer suggestions if they are not. 
This function requires that the first few letters of the generic name and epithet are spelled correctly. It will run a spell check against nearly all published plant name spellings, and search for the most similar spelling within these lists if material is not found. 
It will operate on both pieces of the binomial separately, and can work to identify the species within the context of genus. 

```{r check spelling of binomial and family, eval = F}
p <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
data <- spell_check(data, path = p)
```

A similar check is to determine that the author whom is cited for describing the species, or transferring it to another genus, is spelled using the standard author abbreviations.
This check operates under a similar manner to **spell_check()**.
The list which is consults *is* comprehensive, within a few years, of all taxonomists whom have published plant species. 

```{r check spelling of author, eval = F}

# we want to introduce a single space after the final given name letter of
# an author abbreviation and the surname. In order to do these, we must 
# be sure that the surname is not abbreviated. The true regex which is required
# to do this is somewhat difficult, and we will hack it with a 'trailed' variable

apdc_bag <- c('A.DeCandolle', 'A.P.DeCandolle',  
              'A.P.Y.DeCandolle', 'A.P.DeCandolle.')

trailed <- vector(mode = 'character', length = length(apdc_bag))
trailed[grep('\\.$', apdc_bag)] <- '.'
 # identify which abbreviations have a trailing period

apdc_bag_NTRAIL <- sub('\\.$', '', apdc_bag) # remove the trailing periods
apdc_bag_NTRAIL <- sub('\\.(?!.*\\.)', ". ", 
    apdc_bag_NTRAIL, perl = T) # identify the last period in the name, and add a space after it

paste0(apdc_bag_NTRAIL, trailed)



# when processing we need to perform a few steps

# identify each individual author '()', '&'

words <- c('(Pursh) J.M. Coult. & Rose')
pieces <- strsplit(words, split = '\\) | & ')
pieces <- sub('\\(', "", unlist(pieces))

# to each author abbreviation ensure to match from start ('^') to end ($) of string.
pieces

# identify pieces which are not in the look up list.
L <- length(pieces)
matched <- vector(mode = 'logical', length = L)
for(i in 1:L){
 if(length (grep("^J.M. Coult.$", pieces[i]) ) == 1) {
   matched[i] <- TRUE
   } else {
    matched[i] <- FALSE
    }
}

# create column 'Issues'; to flag specific names
if(any(matched == FALSE)) {
  Issues <- paste(pieces[which(matched == FALSE)], '-? ', collapse = '')
  } else {
    Issues <- 'None'
}

```

After BarnebyLives! has verified the spelling of the species it will submit it to Plants of the World Online to determine whether a more current and accepted name has been applied. 
BL! will not automatically over-write your submitted species, and it is important that you interpret the results of query.
Especially as it is possible that **spell_check** has mis-matched your material to another name. 

Searches for synonym to species
```{r Search for synonyms to species, eval = F}

names <- sf::st_drop_geometry(data) %>% 
  pull(Full_name)

dat_out <- lapply(names,
      powo_searcher)
pow_res <- bind_rows(dat_out)
```

The final process in the taxonomic step is to ensure that the spellings of any species noted in the *vegetation*, or *associates* fields are accurate. These *will not* then be submitted to Kew, as the fields could quickly overwhelm the API. 

```{r check spellings of vegetation and associated species, eval = F}

```


## Directions

directions to a parking spot can be acquired from Google Maps; however this implies the location can be driven to in the first place. 
This will require interactive alterations from the user.

```{r site directions, eval = F}
SoS_gkey = Sys.getenv("Sos_gkey")

directions <- directions_grabber(data, api_key = SoS_gkey)
```


## Export collections

We will write these data to google sheets for our examples. 

```{r write out data to googlesheets4}

df <- sf::st_drop_geometry(directions)
# we will add these data onto our final sheet.  THIS IS THE LAST STEP OF THIS TUTORIAL
sheet_append('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M', 
             sheet = 'Processed - Examples', data = df) 

```
We can also export collections as either (or both!) a 'shapefile' or KML for use in GIS or GoogleEarth.

```{r write out collections in a spatial data format}

```


