message(crayon::green('Starting to write out final files for:',
prods[i], format(Sys.time(), "%X")))
fname <- file.path(outdir, paste0(cellname, ".tif"))
terra::makeTiles(virtualRast_sub, tile_cellsV, filename = fname, na.rm = F)
# remove connection to the vrt
rm(virtualRast_sub)
# try and force garbage collection
# remove extracted dir.
unlink(file.path(dirname(f[i]), prods[i]), recursive = TRUE)
gc()
}
}
}
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
#' e.g. all directories of 'aspect' rasters will go into a single 'aspect' directory.
#' @examples \dontrun{
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
#' }
#' @export
data_setup <- function(path, pathOut, bound, cleanup){
if(missing(path)){path <- './geodata_raw'}
if(missing(pathOut)){pathOut <- '.'}
dir.create(file.path(pathOut, 'geodata'), showWarnings = FALSE)
if(missing(cleanup)){cleanup = FALSE}
# create the extent which we are operating in
bb_vals <- c(min(bound$x), max(bound$x), min(bound$y), max(bound$y))
bound <- bound |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
# decompress all of the archives so we can readily read them into R.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
##### now crop the data to the extents of analysis. ####
mason(path, pathOut, bound, bb_vals)
## now combine all of the administrative data into a single vector file.
make_it_political(path, pathOut, tile_cells)
#### process the GMBA data
process_gmba(path, pathOut, tile_cells)
### crop geographic place name database to extent
process_gnis(path, pathOut, bound)
## crop PADUS to domain
# process_padus(path, pathOut, tile_cells)
## geological map
geological_map(path, pathOut, tile_cells)
## Process grazing allotments
process_grazing_allot(path, pathOut, tile_cells)
## Public land survey system
#  process_plss(path, pathOut, tile_cells)
# remove the extracted zip files
dirs <- list.dirs('geodata_raw', recursive = FALSE)
lapply(dirs, unlink, recursive = TRUE)
if(cleanup==TRUE){
# remove original zip files.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
}
}
#' e.g. all directories of 'aspect' rasters will go into a single 'aspect' directory.
#' @examples \dontrun{
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
#' }
#' @export
data_setup <- function(path, pathOut, bound, cleanup){
if(missing(path)){path <- './geodata_raw'}
if(missing(pathOut)){pathOut <- '.'}
dir.create(file.path(pathOut, 'geodata'), showWarnings = FALSE)
if(missing(cleanup)){cleanup = FALSE}
# create the extent which we are operating in
bb_vals <- c(min(bound$x), max(bound$x), min(bound$y), max(bound$y))
bound <- bound |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
# decompress all of the archives so we can readily read them into R.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
##### now crop the data to the extents of analysis. ####
mason(path, pathOut, bound, bb_vals)
## now combine all of the administrative data into a single vector file.
make_it_political(path, pathOut, tile_cells)
#### process the GMBA data
process_gmba(path, pathOut, tile_cells)
### crop geographic place name database to extent
process_gnis(path, pathOut, bound)
## crop PADUS to domain
# process_padus(path, pathOut, tile_cells)
## geological map
geological_map(path, pathOut, tile_cells)
## Process grazing allotments
process_grazing_allot(path, pathOut, tile_cells)
## Public land survey system
#  process_plss(path, pathOut, tile_cells)
# remove the extracted zip files
dirs <- list.dirs('geodata_raw', recursive = FALSE)
lapply(dirs, unlink, recursive = TRUE)
if(cleanup==TRUE){
# remove original zip files.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
}
}
bound <- data.frame(
y = c(42, 42, 44, 44, 42),
x = c(-117, -119, -119, -117, -117)
)
data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
View(bound)
View(bound)
bound <- data.frame(
y = c(30.1, 30.1, 49.5, 49.5, 30.1),
x = c(-126, -82, -82, -126, -126)
)
bb_vals <- c(min(bound$x), max(bound$x), min(bound$y), max(bound$y))
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
bound <- data.frame(
y = c(30, 30, 50, 50, 30),
x = c(-85, -125, -125, -85, -85)
) |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
#' e.g. all directories of 'aspect' rasters will go into a single 'aspect' directory.
#' @examples \dontrun{
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
#' }
#' @export
data_setup <- function(path, pathOut, bound, cleanup){
if(missing(path)){path <- './geodata_raw'}
if(missing(pathOut)){pathOut <- '.'}
dir.create(file.path(pathOut, 'geodata'), showWarnings = FALSE)
if(missing(cleanup)){cleanup = FALSE}
# create the extent which we are operating in
bb_vals <- c(min(bound$x), max(bound$x), min(bound$y), max(bound$y))
bound <- bound |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
# decompress all of the archives so we can readily read them into R.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
##### now crop the data to the extents of analysis. ####
mason(path, pathOut, bound, bb_vals)
## now combine all of the administrative data into a single vector file.
make_it_political(path, pathOut, tile_cells)
#### process the GMBA data
process_gmba(path, pathOut, tile_cells)
### crop geographic place name database to extent
process_gnis(path, pathOut, bound)
## crop PADUS to domain
# process_padus(path, pathOut, tile_cells)
## geological map
geological_map(path, pathOut, tile_cells)
## Process grazing allotments
process_grazing_allot(path, pathOut, tile_cells)
## Public land survey system
#  process_plss(path, pathOut, tile_cells)
# remove the extracted zip files
dirs <- list.dirs('geodata_raw', recursive = FALSE)
lapply(dirs, unlink, recursive = TRUE)
if(cleanup==TRUE){
# remove original zip files.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
}
}
#'
#' @description for projects with large spatial domains or using relatively high resolution data, this will help
#'
#' you make virtual tiles which do not need to be held in memory for the project.
#' @param path the input directory with all geographic data.
#' @param pathOut the output directory for the final data product to go.
#' Fn will automatically create folders for each product type.
#' @param bound these extracted from argument to `data_setup` bound.
#' @param bb_vals these extracted from argument to `data_setup` bound.
#' @keywords internal
mason <- function(path, pathOut, bound, bb_vals){
# use tiles to create many smaller rasters, rather than one really big raster.
mt <- make_tiles(bound, bb_vals)
tile_cells <- mt$tile_cells
tile_cellsV <- mt$tile_cellsV
paths2rast <- file.path(dirin, list.files(dirin,  recursive = T, pattern = '[.]tar'))
prods <- c('aspect', 'dem', 'geom', 'slope')
for (i in seq_along(1:length(prods))){
outdir <- file.path(dirout, prods[i])
if(!dir.exists(outdir)){
dir.create(outdir) # test the path works before running the big steps...
# extract all data and temporarily dump into a single directory
message(crayon::green('Beginning extraction of files:',
prods[i], format(Sys.time(), "%X")))
f <- paths2rast[grep(prods[i], paths2rast)]
temp <- file.path(dirname(f[i]), prods[i])
sapply(X = f, FUN = untar, exdir = temp)
# now form a VRT, meaning files don't need to be read into active memory (RAM)
# all at once. Now crop all files to the extent of the spatial domain we are
# setting the program up for.
paths <- file.path(temp, list.files(temp, pattern = '[.]tif$', recursive = TRUE))
virtualRast <- terra::vrt(paths)
virtualRast_sub <- terra::crop(virtualRast, terra::ext(tile_cellsV))
# set file names
columns <- terra::values(tile_cellsV)
cellname <- columns[,'cellname']
# write out product
message(crayon::green('Starting to write out final files for:',
prods[i], format(Sys.time(), "%X")))
fname <- file.path(outdir, paste0(cellname, ".tif"))
terra::makeTiles(virtualRast_sub, tile_cellsV, filename = fname, na.rm = F)
# remove connection to the vrt
rm(virtualRast_sub)
# try and force garbage collection
# remove extracted dir.
unlink(file.path(dirname(f[i]), prods[i]), recursive = TRUE)
gc()
}
}
}
#' e.g. all directories of 'aspect' rasters will go into a single 'aspect' directory.
#' @examples \dontrun{
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
#' }
#' @export
data_setup <- function(path, pathOut, bound, cleanup){
if(missing(path)){path <- './geodata_raw'}
if(missing(pathOut)){pathOut <- '.'}
dir.create(file.path(pathOut, 'geodata'), showWarnings = FALSE)
if(missing(cleanup)){cleanup = FALSE}
# create the extent which we are operating in
bb_vals <- c(min(bound$x), max(bound$x), min(bound$y), max(bound$y))
bound <- bound |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
# decompress all of the archives so we can readily read them into R.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
##### now crop the data to the extents of analysis. ####
mason(path, pathOut, bound, bb_vals)
## now combine all of the administrative data into a single vector file.
make_it_political(path, pathOut, tile_cells)
#### process the GMBA data
process_gmba(path, pathOut, tile_cells)
### crop geographic place name database to extent
process_gnis(path, pathOut, bound)
## crop PADUS to domain
# process_padus(path, pathOut, tile_cells)
## geological map
geological_map(path, pathOut, tile_cells)
## Process grazing allotments
process_grazing_allot(path, pathOut, tile_cells)
## Public land survey system
#  process_plss(path, pathOut, tile_cells)
# remove the extracted zip files
dirs <- list.dirs('geodata_raw', recursive = FALSE)
lapply(dirs, unlink, recursive = TRUE)
if(cleanup==TRUE){
# remove original zip files.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
}
}
bound <- data.frame(
y = c(42, 42, 44, 44, 42),
x = c(-117, -119, -119, -117, -117)
)
data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
bound <- data.frame(
y = c(30, 30, 50, 50, 30),
x = c(-85, -125, -125, -85, -85)
) |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
#' e.g. all directories of 'aspect' rasters will go into a single 'aspect' directory.
#' @examples \dontrun{
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
#' }
#' @export
data_setup <- function(path, pathOut, bound, cleanup){
if(missing(path)){path <- './geodata_raw'}
if(missing(pathOut)){pathOut <- '.'}
dir.create(file.path(pathOut, 'geodata'), showWarnings = FALSE)
if(missing(cleanup)){cleanup = FALSE}
# create the extent which we are operating in
bb_vals <- c(min(bound$x), max(bound$x), min(bound$y), max(bound$y))
bound <- bound |>
sf::st_as_sf(coords = c('x', 'y'), crs = 4326) |>
sf::st_bbox() |>
sf::st_as_sfc()
return(bound)
# decompress all of the archives so we can readily read them into R.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
##### now crop the data to the extents of analysis. ####
mason(path, pathOut, bound, bb_vals)
## now combine all of the administrative data into a single vector file.
make_it_political(path, pathOut, tile_cells)
#### process the GMBA data
process_gmba(path, pathOut, tile_cells)
### crop geographic place name database to extent
process_gnis(path, pathOut, bound)
## crop PADUS to domain
# process_padus(path, pathOut, tile_cells)
## geological map
geological_map(path, pathOut, tile_cells)
## Process grazing allotments
process_grazing_allot(path, pathOut, tile_cells)
## Public land survey system
#  process_plss(path, pathOut, tile_cells)
# remove the extracted zip files
dirs <- list.dirs('geodata_raw', recursive = FALSE)
lapply(dirs, unlink, recursive = TRUE)
if(cleanup==TRUE){
# remove original zip files.
zzzs <- file.path(path, list.files(path = path, pattern = '*.[.]zip$'))
lapply(zzzs, FUN = function(x){
out <- gsub('[.]zip', '' , x)
unzip(x, exdir = out)}
)
}
}
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' ob <- data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE
ob
ob <- data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
#' bound <- data.frame(
#'   y = c(42, 42, 44, 44, 42),
#'   x = c(-117, -119, -119, -117, -117)
#' )
#'
#' bound <- data_setup(path = './geodata_raw', bound = bound, cleanup = FALSE)
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
#'
#' @description for projects with large spatial domains or using relatively high resolution data, this will help
#'
#' you make virtual tiles which do not need to be held in memory for the project.
#' @param path the input directory with all geographic data.
#' @param pathOut the output directory for the final data product to go.
#' Fn will automatically create folders for each product type.
#' @param bound these extracted from argument to `data_setup` bound.
#' @param bb_vals these extracted from argument to `data_setup` bound.
#' @keywords internal
mason <- function(path, pathOut, bound, bb_vals){
# use tiles to create many smaller rasters, rather than one really big raster.
mt <- make_tiles(bound, bb_vals)
tile_cells <- mt$tile_cells
tile_cellsV <- mt$tile_cellsV
paths2rast <- file.path(path, list.files(path,  recursive = T, pattern = '[.]tar'))
prods <- c('aspect', 'dem', 'geom', 'slope')
for (i in seq_along(1:length(prods))){
outdir <- file.path(pathOut, prods[i])
if(!dir.exists(outdir)){
dir.create(outdir) # test the path works before running the big steps...
# extract all data and temporarily dump into a single directory
message(crayon::green('Beginning extraction of files:',
prods[i], format(Sys.time(), "%X")))
f <- paths2rast[grep(prods[i], paths2rast)]
temp <- file.path(dirname(f[i]), prods[i])
sapply(X = f, FUN = untar, exdir = temp)
# now form a VRT, meaning files don't need to be read into active memory (RAM)
# all at once. Now crop all files to the extent of the spatial domain we are
# setting the program up for.
paths <- file.path(temp, list.files(temp, pattern = '[.]tif$', recursive = TRUE))
virtualRast <- terra::vrt(paths)
virtualRast_sub <- terra::crop(virtualRast, terra::ext(tile_cellsV))
# set file names
columns <- terra::values(tile_cellsV)
cellname <- columns[,'cellname']
# write out product
message(crayon::green('Starting to write out final files for:',
prods[i], format(Sys.time(), "%X")))
fname <- file.path(outdir, paste0(cellname, ".tif"))
terra::makeTiles(virtualRast_sub, tile_cellsV, filename = fname, na.rm = F)
# remove connection to the vrt
rm(virtualRast_sub)
# try and force garbage collection
# remove extracted dir.
unlink(file.path(dirname(f[i]), prods[i]), recursive = TRUE)
gc()
}
}
}
mason(
dirin = '/media/steppe/hdd/BL_sandbox/geodata_raw',
dirout = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
mason(
path  = '/media/steppe/hdd/BL_sandbox/geodata_raw',
pathOut = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
mason(
path  = '/media/steppe/hdd/BL_sandbox/geodata_raw',
pathOut = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
mason(
path  = '/media/steppe/hdd/BL_sandbox/geodata_raw',
pathOut = '/media/steppe/hdd/BL_sandbox/geodata',
bb_vals = bb_vals, bound = bound
)
# remotes::install_github('sagesteppe/BarnebyLives')
library(BarnebyLives)
library(tidyverse)
library(sf)
library(terra)
# I am using R markdown so want to be really sure save data to the correct location
# so I will use an absolute path
download_data(path = '/media/steppe/hdd/BL_sandbox/geodata_raw')
# devtools::install_github('sagesteppe/BarnebyLives', force = TRUE)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
library(textclean)
?download_data
# I am using R markdown so want to be really sure save data to the correct location
# so I will use an absolute path
download_data(path = '/media/steppe/hdd/BL_sandbox/geodata_raw')
remotes::install_github('sagesteppe/BarnebyLives')
