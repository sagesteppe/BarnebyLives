} else {
possible_genus_Tag <-
gen_strings[which.min(adist(genus, gen_strings))]
}
# is species clean
if (any(grep(x = spe_strings, pattern = paste0('^', species, '$')))) {
clean_species_Tag <- species
} else {
possible_species_Tag <-
spe_strings[which.min(adist(species, spe_strings))]
}
# if both the genus and species name are present, we could be missing it from the DB
if (exists('clean_genus_Tag') & exists ('clean_species_Tag'))
{
return(data.frame(
Query = x, Result = binom, Match = 'Suspected missing from ref DB'))
} else { # if one is not clean search them with the 'cleaned' up versions
combos <- ls()[grep(ls(), pattern = 'Tag')]
search_q <-
combos[c(grep(combos, pattern = 'genus'),
grep(combos, pattern = 'species'))]
search_nom <- paste(unlist(mget(search_q)), collapse = " ")
if (any(grep(x = epiLKPtab$scientificName, pattern = search_nom, fixed = T))) {
return(data.frame(Query = x, Result = search_nom, Match = 'fuzzy'))
} else{
possible_binomial <-
epiLKPtab[which.min(adist(search_nom, epiLKPtab$scientificName)), 'scientificName'] |>
as.character()
return(data.frame(Query = x, Binomial = possible_binomial, Match = 'fuzzy'))
}
}
}
}
}
abbrevs <- read.csv('/hdd/Barneby_Lives-dev/taxonomic_data_raw/ipni_author_abbreviations.csv')
trailed <- vector(mode = 'character', length = nrow(abbrevs))
trailed[grep('\\.$', abbrevs$author_abbrevation)] <- '.'
abbrevs_spaced <- sub('\\.$', '', abbrevs$author_abbrevation) # remove the trailing periods
abbrevs_notrail <- sub('\\.(?!.*\\.)', ". ",
abbrevs_spaced, perl = T) # identify the last period in the name, and add a space after it
abbrevs <- paste0(abbrevs_notrail, trailed)
#usethis::use_data(abbrevs)
write.csv(abbrevs, row.names = F, '../taxonomic_data/abbrevs.csv')
#usethis::use_data(abbrevs)
write.csv(abbrevs, row.names = F, '/hdd/Barneby_Lives-dev/taxonomic_data/abbrevs.csv')
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
usethis::use_rmarkdown_template(
template_name = "Template Name",
template_dir = NULL,
template_description = "A description of the template",
template_create_dir = FALSE
)
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
quit()
library(BarnebyLives)
library(BarnebyLives)
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
collection_examples
associate_dropper(collection_examples, Binomial = Full_name)
associate_dropper(collection_examples, Binomial = 'Full_name')
R CMD CHECK
R CMD CHECK()
devtools::install_github('sagesteppe/BarnebyLives')
library(tidyverse) # data operations
library(BarnebyLives) # for helping accession collections
data <- read.csv('data/test_data.csv', na.strings = "") %>%
drop_na(c('Longitude', 'Latitude', 'Date_digital')) %>%
unite(col = 'Scientific_name', c(Binomial, Infrarank, Infraspecies), na.rm=TRUE, sep = " ", remove = F)
n_families <- data %>%
group_by(Family) %>%
count() %>%
nrow() # 74 families
n_genera <- data %>%
separate(Scientific_name, into = c('Genus', 'Epithet') , remove = FALSE, extra = 'drop') %>%
group_by(Genus) %>%
count() %>%
nrow() # 292 Genera
n_spp <- data %>%
group_by(Binomial) %>%
count() %>%
nrow() # 616 species
n_infraspecies <- data %>%
drop_na(Infraspecies) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 66 distinct infraspecies
n_sp_authors <- data %>%
drop_na(Binomial_authority) %>%
count() %>% # 557 groups of authors
pull()
n_infra_sp_auths <- data %>%
drop_na(Infraspecific_authority) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 22 distinct infra species author groups
n_vegetation_fields <- data %>%
drop_na(Vegetation) %>%
distinct(Vegetation) |>
nrow()
n_associates_fields <- data %>%
drop_na(Associates) %>%
distinct(Associates) |>
nrow()
n_sites <- data %>%
distinct(Latitude, Longitude) %>%
nrow()
time_split_binomials <- system.time({ # split up names into their components
data <- split_binomial(data, 'Scientific_name')
})
time_dms2dd <- system.time({ # if necessary convert coordinates in degrees minutes second to decimal degrees
data <- dms2dd(data, dms = F)
})
time_autofill_checker <- system.time({ # has the spreadsheet software auto-incremented coordinate values?
data <- autofill_checker(data)
})
time_coords2sf <- system.time({ # create a spatial (simple features) object
data <- coords2sf(data)
})
p2geo <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
time_political_grabber <- system.time({ # grab political information for collection
data <- political_grabber(data, y = 'Collection_number', path = p2geo)
})
time_physical_grabber <- system.time({ # grab sites physical information
data <- physical_grabber(data, path = p2geo)
})
time_site_writer <- system.time({ # write site location notes
data <- site_writer(data, path = p2geo)
})
p2tax <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
time_spell_check <- system.time({ # ensure appropriate spellings of the species
data <- spell_check(data, column = 'Full_name', path = p2tax)
})
View(data)
View(data)
data <- read.csv('data/test_data.csv', na.strings = "") %>%
drop_na(c('Longitude', 'Latitude', 'Date_digital')) %>%
unite(col = 'Scientific_name', c(Binomial, Infrarank, Infraspecies), na.rm=TRUE, sep = " ", remove = F)
View(data)
n_families <- data %>%
group_by(Family) %>%
count() %>%
nrow() # 74 families
n_genera <- data %>%
separate(Scientific_name, into = c('Genus', 'Epithet') , remove = FALSE, extra = 'drop') %>%
group_by(Genus) %>%
count() %>%
nrow() # 292 Genera
n_spp <- data %>%
group_by(Binomial) %>%
count() %>%
nrow() # 616 species
n_infraspecies <- data %>%
drop_na(Infraspecies) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 66 distinct infraspecies
n_sp_authors <- data %>%
drop_na(Binomial_authority) %>%
count() %>% # 557 groups of authors
pull()
n_infra_sp_auths <- data %>%
drop_na(Infraspecific_authority) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 22 distinct infra species author groups
n_vegetation_fields <- data %>%
drop_na(Vegetation) %>%
distinct(Vegetation) |>
nrow()
n_associates_fields <- data %>%
drop_na(Associates) %>%
distinct(Associates) |>
nrow()
# number of collection sites
n_sites <- data %>%
distinct(Latitude, Longitude) %>%
nrow()
time_split_binomials <- system.time({ # split up names into their components
data <- split_binomial(data, 'Scientific_name')
})
View(data)
split_binomial
## devtools::install_github('sagesteppe/BarnebyLives')
devtools::install_github('sagesteppe/BarnebyLives')
library(tidyverse) # data operations
library(BarnebyLives) # for helping accession collections
data <- read.csv('data/test_data.csv', na.strings = "") %>%
drop_na(c('Longitude', 'Latitude', 'Date_digital')) %>%
unite(col = 'Scientific_name', c(Binomial, Infrarank, Infraspecies), na.rm=TRUE, sep = " ", remove = F)
n_families <- data %>%
group_by(Family) %>%
count() %>%
nrow() # 74 families
n_genera <- data %>%
separate(Scientific_name, into = c('Genus', 'Epithet') , remove = FALSE, extra = 'drop') %>%
group_by(Genus) %>%
count() %>%
nrow() # 292 Genera
n_spp <- data %>%
group_by(Binomial) %>%
count() %>%
nrow() # 616 species
n_infraspecies <- data %>%
drop_na(Infraspecies) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 66 distinct infraspecies
n_sp_authors <- data %>%
drop_na(Binomial_authority) %>%
count() %>% # 557 groups of authors
pull()
n_infra_sp_auths <- data %>%
drop_na(Infraspecific_authority) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 22 distinct infra species author groups
n_vegetation_fields <- data %>%
drop_na(Vegetation) %>%
distinct(Vegetation) |>
nrow()
n_associates_fields <- data %>%
drop_na(Associates) %>%
distinct(Associates) |>
nrow()
# number of collection sites
n_sites <- data %>%
distinct(Latitude, Longitude) %>%
nrow()
time_split_binomials <- system.time({ # split up names into their components
data <- split_binomial(data, 'Scientific_name')
})
time_dms2dd <- system.time({ # if necessary convert coordinates in degrees minutes second to decimal degrees
data <- dms2dd(data, dms = F)
})
time_autofill_checker <- system.time({ # has the spreadsheet software auto-incremented coordinate values?
data <- autofill_checker(data)
})
time_coords2sf <- system.time({ # create a spatial (simple features) object
data <- coords2sf(data)
})
p2geo <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
time_political_grabber <- system.time({ # grab political information for collection
data <- political_grabber(data, y = 'Collection_number', path = p2geo)
})
time_physical_grabber <- system.time({ # grab sites physical information
data <- physical_grabber(data, path = p2geo)
})
time_site_writer <- system.time({ # write site location notes
data <- site_writer(data, path = p2geo)
})
p2tax <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
time_spell_check <- system.time({ # ensure appropriate spellings of the species
data <- spell_check(data, column = 'Scientific_name', path = p2tax)
})
time_family_spell_check <- system.time({ # ensure appropriate spelling of the family
data <- family_spell_check(data, path = p2tax)
})
time_author_check <- system.time({ # ensure authorities are spelled-noted correctly
data <- author_check(data, path = p2tax)
})
time_associate_dropper_veg <- system.time({ # ensure associated species are spelled correctly.
data <- associates_spell_check(data, 'Vegetation', p2tax)
})
time_associate_dropper_ass <- system.time({ # ensure associated species are spelled correctly.
data <- associates_spell_check(data, 'Associates', p2tax)
})
time_associate_dropper <- system.time({ # remove the focal taxon from the noted associates
data <- associate_dropper(data, 'Full_name')
})
time_date_parser <- system.time({ # parse dates into museum formats
data <- date_parser(data, coll_date = 'Date_digital')
})
time_geodata_writer <- system.time({ # write out collection as GoogleEarth object
geodata_writer(data, path = 'data/processed',
filename = 'Herbarium_Collections_2023',
filetype = 'kml')
})
View(data)
#' write out spatial data for collections to Google Earth or QGIS
#'
#' This function will write out a simple labeled vector data (ala a 'shapefile') containing just collection number.
#' More data (e.g. species) can be written out using sf::st_write directly. See ?sf those details.
#' The function defaults to writing Google Earth KML files because these can be viewed online without having to to have a local install of the program.
#' @param x a data frame(/sf/tibble) which has at least undergone the 'dms2dd' and 'coords2sf' functions from BarnebyLives.
#' @param path a location to save the data to. If not supplied defaults to the current working directory.
#' @param filename name of file. if not supplied defaults to appending todays date to 'Collections'
#' @param filetype a file format to save the data to. This is a wrapper for sf::st_write and will support all drivers used there. If not supplied defaults to kml for use with Google Earth.
geodata_writer <- function(x, path, filename, filetype){
if(missing(filetype)){filetype <- 'kml'}
if(missing(filename)){filename <- paste0('HerbariumCollections-', Sys.Date())}
if(missing(path)){fname <- paste0(filename, filetype)} else {
fname <- file.path(path, paste0(filename, '.', filetype))
}
ifelse(!dir.exists(file.path(path)), dir.create(file.path(path)), FALSE)
x <- x |>
dplyr::mutate(
Collector_n_Number = paste(gsub("(*UCP)[^;-](?<!\\b\\p{L})", "", Primary_Collector, perl=TRUE),
Collection_number),
UNIQUEID = paste0(Primary_Collector, Collection_number)) |>
dplyr::select(NAME = Collector_n_Number, Description = UNIQUEID) |>
sf::st_write(dsn = fname, driver = filetype,
delete_dsn = TRUE, quiet = T, append = F)
message(crayon::green('Spatial collection data written to: ', fname))
}
time_geodata_writer <- system.time({ # write out collection as GoogleEarth object
geodata_writer(data, path = 'data/processed',
filename = 'Herbarium_Collections_2023',
filetype = 'kml')
})
rm(p2geo, p2tax)
time_powo_searcher <- readRDS(file = 'data/processed/time_powo_searcher')
time_directions_grabber <- readRDS('data/processed/time_directions_grabber')
associates_spell_check_ass <- system.time({ # ensure associated species are spelled correctly.
data <- associates_spell_check(data, 'Associates', p2tax)
})
library(tidyverse) # data operations
library(BarnebyLives) # for helping accession collections
data <- read.csv('data/test_data.csv', na.strings = "") %>%
drop_na(c('Longitude', 'Latitude', 'Date_digital')) %>%
unite(col = 'Scientific_name', c(Binomial, Infrarank, Infraspecies), na.rm=TRUE, sep = " ", remove = F)
n_families <- data %>%
group_by(Family) %>%
count() %>%
nrow() # 74 families
n_genera <- data %>%
separate(Scientific_name, into = c('Genus', 'Epithet') , remove = FALSE, extra = 'drop') %>%
group_by(Genus) %>%
count() %>%
nrow() # 292 Genera
n_spp <- data %>%
group_by(Binomial) %>%
count() %>%
nrow() # 616 species
n_infraspecies <- data %>%
drop_na(Infraspecies) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 66 distinct infraspecies
n_sp_authors <- data %>%
drop_na(Binomial_authority) %>%
count() %>% # 557 groups of authors
pull()
n_infra_sp_auths <- data %>%
drop_na(Infraspecific_authority) %>%
group_by(Binomial, Infraspecies) %>%
count() %>%
nrow() # 22 distinct infra species author groups
n_vegetation_fields <- data %>%
drop_na(Vegetation) %>%
distinct(Vegetation) |>
nrow()
n_associates_fields <- data %>%
drop_na(Associates) %>%
distinct(Associates) |>
nrow()
# number of collection sites
n_sites <- data %>%
distinct(Latitude, Longitude) %>%
nrow()
time_split_binomials <- system.time({ # split up names into their components
data <- split_binomial(data, 'Scientific_name')
})
time_dms2dd <- system.time({ # if necessary convert coordinates in degrees minutes second to decimal degrees
data <- dms2dd(data, dms = F)
})
time_autofill_checker <- system.time({ # has the spreadsheet software auto-incremented coordinate values?
data <- autofill_checker(data)
})
time_coords2sf <- system.time({ # create a spatial (simple features) object
data <- coords2sf(data)
})
p2geo <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'
time_political_grabber <- system.time({ # grab political information for collection
data <- political_grabber(data, y = 'Collection_number', path = p2geo)
})
time_physical_grabber <- system.time({ # grab sites physical information
data <- physical_grabber(data, path = p2geo)
})
time_site_writer <- system.time({ # write site location notes
data <- site_writer(data, path = p2geo)
})
p2tax <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'
time_spell_check <- system.time({ # ensure appropriate spellings of the species
data <- spell_check(data, column = 'Scientific_name', path = p2tax)
})
time_family_spell_check <- system.time({ # ensure appropriate spelling of the family
data <- family_spell_check(data, path = p2tax)
})
time_author_check <- system.time({ # ensure authorities are spelled-noted correctly
data <- author_check(data, path = p2tax)
})
associates_spell_check_veg <- system.time({ # ensure associated species are spelled correctly.
data <- associates_spell_check(data, 'Vegetation', p2tax)
})
associates_spell_check_ass <- system.time({ # ensure associated species are spelled correctly.
data <- associates_spell_check(data, 'Associates', p2tax)
})
time_associate_dropper <- system.time({ # remove the focal taxon from the noted associates
data <- associate_dropper(data, 'Full_name')
})
time_date_parser <- system.time({ # parse dates into museum formats
data <- date_parser(data, coll_date = 'Date_digital')
})
time_geodata_writer <- system.time({ # write out collection as GoogleEarth object
geodata_writer(data, path = 'data/processed',
filename = 'Herbarium_Collections_2023',
filetype = 'kml')
})
#' write out spatial data for collections to Google Earth or QGIS
#'
#' This function will write out a simple labeled vector data (ala a 'shapefile') containing just collection number.
#' More data (e.g. species) can be written out using sf::st_write directly. See ?sf those details.
#' The function defaults to writing Google Earth KML files because these can be viewed online without having to to have a local install of the program.
#' @param x a data frame(/sf/tibble) which has at least undergone the 'dms2dd' and 'coords2sf' functions from BarnebyLives.
#' @param path a location to save the data to. If not supplied defaults to the current working directory.
#' @param filename name of file. if not supplied defaults to appending todays date to 'Collections'
#' @param filetype a file format to save the data to. This is a wrapper for sf::st_write and will support all drivers used there. If not supplied defaults to kml for use with Google Earth.
geodata_writer <- function(x, path, filename, filetype){
if(missing(filetype)){filetype <- 'kml'}
if(missing(filename)){filename <- paste0('HerbariumCollections-', Sys.Date())}
if(missing(path)){fname <- paste0(filename, filetype)} else {
fname <- file.path(path, paste0(filename, '.', filetype))
}
ifelse(!dir.exists(file.path(path)), dir.create(file.path(path)), FALSE)
x <- x |>
dplyr::mutate(
Collector_n_Number = paste(gsub("(*UCP)[^;-](?<!\\b\\p{L})", "", Primary_Collector, perl=TRUE),
Collection_number),
UNIQUEID = paste0(Primary_Collector, Collection_number)) |>
dplyr::select(NAME = Collector_n_Number, Description = UNIQUEID) |>
sf::st_write(dsn = fname, driver = filetype,
delete_dsn = TRUE, quiet = T, append = F)
message(crayon::green('Spatial collection data written to: ', fname))
}
time_geodata_writer <- system.time({ # write out collection as GoogleEarth object
geodata_writer(data, path = 'data/processed',
filename = 'Herbarium_Collections_2023',
filetype = 'kml')
})
rm(p2geo, p2tax)
time_powo_searcher <- readRDS(file = 'data/processed/time_powo_searcher')
time_directions_grabber <- readRDS('data/processed/time_directions_grabber')
time_trials <- data.frame(as.matrix(do.call(rbind, mget(ls(pattern = '^time'))))) %>%
rownames_to_column('Function') %>%
select(-user.child, -sys.child) %>%
mutate(Function = str_remove(Function, 'time_')) %>%
mutate(Module = case_when(
Function %in% c('associate_dropper', 'split_binomials', 'date_parser') ~ 'Style',
Function %in% c('autofill_checker', 'coords2sf', 'dms2dd', 'physical_grabber', 'time_geodata_writer',
'political_grabber', 'site_writer', 'geodata_writer', 'directions_grabber') ~ 'Geospatial',
Function %in% c('spell_check', 'family_spell_check', 'author_check',  'powo_searcher',
'associates_spell_check_veg', 'associates_spell_check_ass') ~ 'Taxonomic',
Function %in% c('time_label_maker', 'time_shipping_manifest', 'time_label_assembly') ~ 'Labels'
),
Group = if_else(Function %in% c('powo_searcher', 'directions_grabber'), 'Online', 'Local')
)
# save these as RDS so operations do not need to be run each time document knits
saveRDS(time_trials, file = 'data/processed/time_trials')
rm(time_trials)
rm(list=ls(pattern = 'time'))
time_trials <- readRDS('data/processed/time_trials')
tt_local <- time_trials[time_trials$Group=='Local',]
time_label_gen <- readRDS('data/processed/time_label_gen')[['elapsed']]
time_4perpage <- gsub('user.*$', '', readLines('labels/4labsperpage.txt'))[1]
time_final <- gsub('user.*$', '', readLines('labels/process2final.txt'))[1]
minutemen <- function(x){
lkp <- 1:60
names(lkp) <-  c('one', 'two', 'three', 'four', 'five', 'six',
'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 13:60)
names(lkp) [ round(x/60, digits = 0) ]
}
minutemen(sum( time_trials[time_trials$Group=='Local', 'elapsed']))
database_templates <- read.csv('data-raw/Fields.csv')
usethis::use_data(database_templates)
usethis::use_data(database_templates, overwrite = TRUE)
database_templates <- read.csv('data-raw/Fields.csv')
usethis::use_data(database_templates)
usethis::use_data(database_templates, overwrite = T)
load("/media/steppe/hdd/BarnebyLives/data/database_templates.rda")
View(database_templates)
roxygen2::roxygenise()
